---
title: 'ECO 395M: StatLearning Exercise 1'
author: "Joseph Williams, Aahil Navroz, Qi Suqian"
date: "`r Sys.Date()`"
output: html_document
---


## 1) Data visualization: flights at ABIA

For this question we wanted to help fliers (say fliers in 2009) build intuition or 'rules of thumb' they can use when choosing between airline companies. To begin we want the data to correspond to recognizable names, so we mapped UniqueCarrier to airline brands or their parent brands.  Here's a breakdown of which major carriers are running the most flights out of ABIA.


```{r setup, message=FALSE, echo=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)

#codes = read.csv('./data/airport-codes.csv')
#abia_data = read.csv('./data/ABIA.csv', header = TRUE)

#Mapping to tie airlines to carrier codes
carrier_lookup <- data.frame(
  UniqueCarrier = sort(unique(abia_data$UniqueCarrier)),
  Airline = c("Pinnacle", "American", "JetBlue", "North-Western", "Delta", "Alaska", "Frontier", "American", "Celeste", "American", "SkyWest", "United", "SilkAir", "Southwest", "JSX", "United")
)

#Merge code to airline name
abia_data = merge(abia_data, carrier_lookup, by = "UniqueCarrier")

#Lets check using airline == Southwest
data_check = abia_data %>% 
  select(UniqueCarrier, Airline) %>% 
  filter(Airline == "Southwest")
#print(unique(data_check$UniqueCarrier))

#Lets see what the most popular major airlines are
main_airlines = c("United", "Southwest", "JetBlue", "Delta", "American", "Frontier")

flights_by_airline = abia_data %>% 
  filter(Airline %in% main_airlines) %>%
  group_by(Airline) %>%
  summarize(TotalFlights = n())


# Use scale_fill_manual() with the vector of colors
ggplot(flights_by_airline, aes(x = Airline, y = TotalFlights, fill = Airline)) +
  geom_col() +
  labs(title = "Total Flights by Major Airline",
       x = "Airline",
       y = "Flights") +
  theme_minimal()

```


Looks like American and Southwest are king... but can they handle the volume!?  Lets look at arrival delays for each company. Given these are arrival delays for flights coming into and out of Austin, overall it will be a fine measure for the timeliness of the airline.

```{r, message=FALSE, echo=FALSE, warning=FALSE}

# Converting DepTime to hour of the day
abia_data$DepHour = floor(abia_data$DepTime / 100)

# Calculate average departure delays by airline and hour
avg_delays = abia_data %>%
  filter(Airline %in% main_airlines) %>%
  group_by(Airline, DepHour) %>%
  summarize(AvgArrDelay = mean(ArrDelay, na.rm = TRUE))

# Plotting average Arrival delay by airline across different hours of the day 
ggplot(avg_delays, aes(x = DepHour, y = AvgArrDelay, color = Airline)) +
  geom_line() +
  geom_point() +
  facet_wrap(~Airline, scales = "fixed", ncol = 3) + 
  theme_minimal() +
  labs(title = "Average Arrival Delays by Airline and Hour",
       x = "Hour of Day",
       y = "Average Delay (Min)") +
  scale_x_continuous(breaks = seq(0, 24, by = 6)) + 
  theme(legend.position = "none")

```

Okay, we're seeing some detail here.  Seems like most companies experience their delays before the hour of 6am.  Since we're looking for rules of thumb.  Lets classify into 'Red Eye' 'Early Morning', '9-5' and 'Evening-Night', and see if we can quantify delay times over periods, rather than specific times.  Some of these averages seem too high, too, lets remove observations where ArrDelay is more than 4 hours, since that usually results in a changed flight for me.  Lets also subtract WeatherDelay, SecurityDelay, and NASDelay from ArrivalDelay since those aren't related to the airline.


```{r, message=FALSE, echo=FALSE, warning=FALSE}

abia_data$DepHour = as.integer(abia_data$DepHour)
#missing_values = sum(is.na(abia_data$DepHour))
#print(missing_values)

abia_data = abia_data[complete.cases(abia_data$DepHour), ]
abia_data = abia_data %>% filter(DepDelay <= 240)

classify_hour <- function(hour) {
  ifelse((hour >= 22 & hour < 24) | (hour >= 0 & hour < 2), "Red-Eye",
         ifelse(hour >= 2 & hour < 9, "Morning",
                ifelse(hour >= 9 & hour < 17, "9-5", "Evening-Night")))
}

abia_data = abia_data %>% 
  mutate(Period = classify_hour(DepHour))


avg_delays_period = abia_data %>%
  filter(Airline %in% main_airlines) %>%
  mutate(WeatherDelay = coalesce(WeatherDelay, 0)) %>%
  mutate(SecurityDelay = coalesce(SecurityDelay, 0)) %>%
  mutate(NASDelay = coalesce(NASDelay, 0)) %>%
  group_by(Airline, Period) %>%
  summarize(AvgArrDelay = mean(ArrDelay - WeatherDelay - SecurityDelay - NASDelay, na.rm = TRUE))



# Define the desired order of the levels for the "Period" variable
desired_order <- c("Morning", "9-5", "Evening-Night", "Red-Eye")

# Reorder the levels of the "Period" variable
avg_delays_period <- avg_delays_period %>%
  mutate(Period = factor(Period, levels = desired_order))

ggplot(avg_delays_period, aes(x = Period, y = AvgArrDelay, fill = Airline)) +
  geom_col() +
  facet_wrap(~Airline, scales = "fixed", ncol = 3) + 
  theme_minimal() +
  labs(title = "Average Arrival Delays by Airline and Period",
       x = "Period",
       y = "Average Delay (Min)") + 
theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))

```

Okay now this is more useful!  Let's see, if cost difference is minimal and its important that my flight goes smoothly, I am brand-indifferent for Morning and 9-5 flights, prefer Frontier for night flights, and will only fly United for red-eyes.  You're welcome, 2009 travelers!

```{r, message=FALSE, echo=FALSE, warning=FALSE}




```

### 2) Wrangling the Olympics

A) What is the 95th percentile of heights for female competitors across all Athletics events (i.e., track and field)?  

```{r, message=FALSE, echo=FALSE, warning=FALSE}
olympics_data = read.csv("./data/olympics_top20.csv")

#A

# Filter for female competitors in Athletics events
unique_female_athletes = olympics_data %>%
  filter(sex == 'F', grepl('Athletics', event)) %>%
  distinct(id, .keep_all = TRUE)

# Calculate the 95th percentile of heights
percentile_95_height = quantile(unique_female_athletes$height, probs = 0.95, na.rm = TRUE)

print(percentile_95_height)


```

B) Which single women's `event` had the greatest variability in competitor's heights across the entire history of the Olympics, as measured by the standard deviation?  

```{r, message=FALSE, echo=FALSE, warning=FALSE}

#B

females = filter(olympics_data, sex == 'F')

# Calculate the standard deviation of heights for each event
std_devs = females %>%
  group_by(event) %>%
  summarize(HeightStdDev = sd(height, na.rm = TRUE)) %>%
  ungroup() %>%
  na.omit()  

# Find the event with the greatest standard deviation in height
max_std_dev = max(std_devs$HeightStdDev, na.rm = TRUE)
event_with_greatest_variability = filter(std_devs, HeightStdDev == max_std_dev)


print(event_with_greatest_variability)


```

C) How has the average age of Olympic swimmers changed over time? Does the trend look different for male swimmers relative to female swimmers?


```{r, message=FALSE, echo=FALSE, warning=FALSE}

swimmers = filter(olympics_data, sport == 'Swimming')

# Calculate the average age of swimmers over time for each gender
avg_age_over_time = swimmers %>%
  group_by(year, sex) %>%
  summarize(AverageAge = mean(age, na.rm = TRUE)) %>%
  ungroup()

# Plot the data with separate lines for male and female swimmers
ggplot(avg_age_over_time, aes(x = year, y = AverageAge, color = sex)) +
  geom_line() +
  labs(title = 'Average Age of Olympic Swimmers Over Time by Gender',
       x = 'Year',
       y = 'Average Age') +
  theme_minimal() 

```

Average age by gender has increased since 1920s for both type's of athletes but began to increase more rapidly for women leading up to year 2000.  Suggesting women are competing at the highest level of sport later in their lives, on average.  This likely a result of increased popularity of woman's sports, effects of title IX.


### 3) K-nearest neighbors: cars  

For each trim, make a plot of RMSE versus K, so that we can see where it bottoms out.  Then for the optimal value of K, show a plot of the fitted model, i.e. predictions vs. x.

```{r, message=FALSE, echo=FALSE, warning=FALSE}


#sclass = read.csv("./data/sclass.csv")

library(tidyverse)
library(caret)
library(modelr)
library(rsample)

set.seed(16)

# Filter for the two trim levels
sclass_350 = sclass %>% filter(trim == '350')
sclass_65_AMG = sclass %>% filter(trim == '65 AMG')

# Split the data for the 350 trim level
split_350 = initial_split(sclass_350, prop = 0.80) 
train_350 = training(split_350)
test_350 = testing(split_350)

# Split the data for the 65 AMG trim level
split_65_AMG = initial_split(sclass_65_AMG, prop = 0.80) 
train_65_AMG = training(split_65_AMG)
test_65_AMG = testing(split_65_AMG)

run_knn = function(train_data, test_data) {
  k_values = seq(2, 100, by = 2) # Define the range of k values
  rmse_values = numeric(length(k_values)) # To store RMSE for each k
  
  for (i in seq_along(k_values)) {
    k = k_values[i]
    # Train the KNN model
    knn_model = train(price ~ mileage, data = train_data, method = "knn",
                       tuneGrid = expand.grid(k = k),
                            trControl = trainControl(method = "none"))
    # Make predictions on the test set
    predictions = predict(knn_model, test_data)
    # Calculate RMSE and store it
    rmse_values[i] = RMSE(predictions, test_data$price)
  }
  
  return(data.frame(k = k_values, RMSE = rmse_values))
}


rmse_results_350 = run_knn(train_350, test_350)


rmse_results_65_AMG = run_knn(train_65_AMG, test_65_AMG)

# Plotting for 350 trim
ggplot(rmse_results_350, aes(x = k, y = RMSE)) +
  geom_line() + geom_point() +
  ggtitle("RMSE vs K for 350 Trim") +
  xlab("K") + ylab("RMSE")

# Plotting for 65 AMG trim
ggplot(rmse_results_65_AMG, aes(x = k, y = RMSE)) +
  geom_line() + geom_point() +
  ggtitle("RMSE vs K for 65 AMG Trim") +
  xlab("K") + ylab("RMSE")

```

We see that the 350 trim yields a higher optimal k.  This could in part be because there is more data from cars with the 350 trim (332 in the training df vs 233 for 65 AMGs).

```{r, message=FALSE, echo=FALSE, warning=FALSE}


# Identify the optimal K for 350 trim
optimal_k_350 = rmse_results_350[which.min(rmse_results_350$RMSE), ]$k

# Identify the optimal K for 65 AMG trim
optimal_k_65_AMG = rmse_results_65_AMG[which.min(rmse_results_65_AMG$RMSE), ]$k

# Function to plot predictions vs mileage for the optimal K
plot_predictions_vs_mileage = function(train_data, test_data, optimal_k, trim_name) {
  # Fit the model using the optimal K
  knn_model_optimal = train(price ~ mileage, data = train_data, method = "knn",
                            tuneGrid = expand.grid(k = optimal_k),
                            trControl = trainControl(method = "none"))
  

  test_data$predicted_price = predict(knn_model_optimal, test_data)
  
  
  ggplot(test_data, aes(x = mileage, y = price)) +
    geom_point(color = "blue", alpha = 0.5) +
    geom_line(aes(y = predicted_price), color = "red") +
    ggtitle(paste("Predictions vs Mileage for", trim_name, "with K =", optimal_k)) +
    xlab("Mileage") + ylab("Price") +
    theme_minimal()
}

# Plot for 350 trim
plot_predictions_vs_mileage(train_350, test_350, optimal_k_350, "350 Trim")

# Plot for 65 AMG trim
plot_predictions_vs_mileage(train_65_AMG, test_65_AMG, optimal_k_65_AMG, "65 AMG Trim")


```
